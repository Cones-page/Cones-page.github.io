<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0045)http://6.869.csail.mit.edu/fa19/schedule.html -->
<html xmlns="http://www.w3.org/1999/xhtml"><head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
<!--	<script async src="https://www.googletagmanager.com/gtag/js?id=G-WLX2Z5QLG8"></script>-->
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-WLX2Z5QLG8');
	</script>




	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

<script type="text/javascript">
$(document).ready(function () {

    if (localStorage.getItem("my_app_name_here-quote-scroll") != null) {
        $(window).scrollTop(localStorage.getItem("my_app_name_here-quote-scroll"));
    }

    $(window).on("scroll", function() {
        localStorage.setItem("my_app_name_here-quote-scroll", $(window).scrollTop());
    });

  });
</script>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
   <title>Cones 2: Customizable Image Synthesis with Multiple Subjects</title>
  <link href="style.css" rel="stylesheet" type="text/css">


  <meta name="description" content="Project page for &#39;Cones 2: Customizable Image Synthesis with Multiple Subjects.&#39;">
  <link rel="icon" href="./pics/wis_logo.jpg">
</head>

<body>
<!--   <p class="title">Cones V2: Customizable Image Synthesis with Multiple Subjects</p>
  <table width="999" border="0" align="center" class="menu" style="margin-bottom: 8px;">
    <tbody>
      <tr>
        <td style="font-size: 17pt;" align="center"></td>
      </tr>
    </tbody>
  </table> -->
	  <table width="999" border="0" align="center" class="menu" style="margin-bottom: 8px;">
    <tbody>
      <tr>  <p class="title">Cones 2: Customizable Image Synthesis with Multiple Subjects</p>
        <td style="font-size: 17pt;" align="center"></td>
      </tr>
 <!--         <tr>
        <td style="font-size: 17pt;" align="center">Preprint. Under review.</td>
      </tr> -->
    </tbody>
  </table>
<p class="author">
        <span class="author"><a target="_blank" href="https://cones-page.github.io">Zhiheng Liu</a>&nbsp;<sup>1*</sup></span>
    <span class="author"><a target="_blank" href="https://cones-page.github.io">Yifei Zhang&nbsp;</a><sup>2*</sup></span>
    <span class="author"><a target="_blank" href="https://shenyujun.github.io">Yujun Shen</a>&nbsp;<sup>3</sup></span>
    <span class="author"><a target="_blank" href="https://cones-page.github.io">Kecheng Zheng</a>&nbsp;<sup>3&nbsp;</sup></span>
    <span class="author"><a target="_blank" href="https://cones-page.github.io">Kai Zhu</a>&nbsp;<sup>1&nbsp;</sup></span>
  <br>  <span class="author"><a target="_blank" href="https://cones-page.github.io">Ruili Feng</a>&nbsp;<sup>1&nbsp;</sup></span>
    <span class="author"><a target="_blank" href="https://cones-page.github.io">Yu Liu</a>&nbsp;<sup>4&nbsp;</sup></span>
<span class="author"><a target="_blank" href="https://cones-page.github.io">Deli Zhao</a>&nbsp;<sup>4&nbsp;</sup></span>
<span class="author"><a target="_blank" href="https://cones-page.github.io">Jingren Zhou</a>&nbsp;<sup>4&nbsp;</sup></span>
<span class="author"><a target="_blank" href="https://cones-page.github.io">Yang Cao</a>&nbsp;<sup>1&nbsp;</sup></span>
<!--  	<span class="author">Zhiheng Liu</a>&nbsp;<sup>*</sup></span>
	<span class="author">Yifei Zhang&nbsp;</a><sup>*</sup></span>
	<span class="author">Yujun Shen</a>&nbsp;</span> -->
<!-- span class="author">Kecheng Zheng</a>&nbsp;</span> -->
<!-- span class="author">Kai Zhu</a>&nbsp;</span> -->
<!-- span class="author">Ruili Feng</a>&nbsp;</span> -->
<!--  <span class="author">Yu Liu</a></span> -->
<!--  <span class="author">Deli Zhao</a></span> -->
<!--  <span class="author">Jingren Zhou</a></span> -->
<!--    <span class="author">Yang Cao</a></span> -->
  </p>
  <table border="0" align="center" class="affiliations" width="1200px">
      <tbody align="center">
    <tr>
        <td></td>
<!--        <td style="text-align: right; width: 17%"><img src="./pics/wis_logo.jpg" height="48" alt=""></td>-->
        <td style="text-align: center; ">&nbsp;<sup>&nbsp;</sup>&nbsp;</sup>&nbsp;</sup>&nbsp;<sup>1&nbsp;&nbsp;</sup>University of Science and Technology of China &nbsp;<sup>2&nbsp;</sup>Shanghai Jiao Tong University &nbsp;<sup>3&nbsp;</sup>Ant Group &nbsp;<sup>4&nbsp;</sup>Alibaba Group  &nbsp;</td>
<!--         <td style="text-align: center; ">&nbsp;<sup>&nbsp;</sup>&nbspWeizmann Institute of Science &nbsp;&nbsp;</td> -->
        <!--    </tr>-->
<!--    <tr>-->
<!--        <td style="text-align: right; width: 17%"></td>-->
<!--        <td style="text-align: left; width:20%; ">&nbsp;<sup>&nbsp;</sup>&nbsp;<sup>2&nbsp;&nbsp;</sup>Meta AI</td>-->
    </tr>
    </tbody></table>

    <table width="999" border="0" align="center" class="menu" style="margin-bottom: 8px;">
      <tbody>
        <tr>
<!--          <td align="center">| <a href="paper_compressed.pdf">Paper</a> | <a href="sm/index.html">Supplementary Material</a> | <a href="https://github.com/omerbt/MultiDiffusion" target="_blank">Code</a> |</td>-->
          <td align="center">| <a href="https://arxiv.org/abs/2305.19327">Paper</a> | <a href="https://github.com/damo-vilab/Cones-V2">Code</a> | Huggingface Demo<sub> (Coming soon)</sub></a> | ModelScope Demo<sub> (Coming soon)</sub></a> |</td>
        </tr>
      </tbody>
    </table>
<div class="container">
      <table width="800" border="0" align="center">
        <tbody>
			<tr>
                <hr>

                <div class="slideshow-container">

                  <div class="mySlides fade" align="center">
                  <!--  <div class="numbertext">2 / 3</div>-->
                    <img src="teaser11.png" alt="" style="width:65%"></a>
                  <!--  <div class="text">Caption Two</div>-->
                  </div>
                  
                  <div class="mySlides fade" align="center">
                  <!--  <div class="numbertext">3 / 3</div>-->
                     <img src="teaser22.png" alt="" style="width:65%"></a>
                  <!--  <div class="text">Caption Three</div>-->
                  </div>
                          <div class="mySlides fade" align="center">
                  <!--  <div class="numbertext">3 / 3</div>-->
                    <img src="teaser33.png" alt="" style="width:65%"></a>
                  <!--  <div class="text">Caption Three</div>-->
                  </div>
                          
                  
                  <a class="prev" onclick="plusSlides(-1)">❮</a>
                  <a class="next" onclick="plusSlides(1)">❯</a>
                  
                  </div>
                  <br>
                  
                  <div style="text-align:center">
                    <span class="dot" onclick="currentSlide(1)"></span>
                    <span class="dot" onclick="currentSlide(2)"></span>
                    <span class="dot" onclick="currentSlide(3)"></span>
                     
                  </div>
 <!--             <img src="pics/project_teaser.png" alt="" width="1000"/>-->
<!--	                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted=""> <source src="pics/demo_nowatermark.mp4" type="video2/mp4"> </video>-->

            </tr>
		<tr>
      <td><p>
        Cones 2 uses a simple yet effective representation to register a subject. The storage space required for each subject is approximately <b><b><i>5 KB</i></b></b>. Moreover, Cones 2 allows for the flexible composition of various subjects <b><b><i>without any model tuning</i></b></b>.
	   <!--  (2) Employing spatial layout, which is very easy to obtain in practice, as a guidance, we can control the specific location of each subject and meanwhile <b><b><i>alleviate the interference</i></b></b> across subjects. -->
      <!-- (3) Our method achieves appealing performance even under some <b><b><i>challenging settings</i></b></b>, such as customizing the synthesis with six or more subjects and exchanging the sunglasses on the two dogs. -->
      </p></td>
    </tr>
		  <tr align="center"></tr>
<tr>
      <td style="padding-left: 20px">
        <video height="500" playsinline="" autoplay="" loop="" preload="" muted=""> <source src="video2.mp4" type="video/mp4"> </video>
      </td>
    </tr>
        </tbody></table>
<!--	    &nbsp;-->
<hr>
  <p><span class="section"><b>Abstract</b></span> </p>
          <p>
              Synthesizing images with user-specified subjects has received growing attention due to its practical applications. Despite the recent success in single subject customization, existing algorithms suffer from high training cost and low success rate along with increased number of subjects. Towards controllable image synthesis with multiple subjects as the constraints, this work studies how to efficiently represent a particular subject as well as how to appropriately compose different subjects. We find that the text embedding regarding the subject token already serves as a simple yet effective representation that supports arbitrary combinations without any model tuning. Through learning a residual on top of the base embedding, we manage to robustly shift the raw subject to the customized subject given various text conditions. We then propose to employ layout, a very abstract and easy-to-obtain prior, as the spatial guidance for subject arrangement. By rectifying the activations in the cross-attention map, the layout appoints and separates the location of different subjects in the image, significantly alleviating the interference across them. Using cross-attention map as the intermediary, we could strengthen the signal of target subjects and weaken the signal of irrelevant subjects within a certain region, significantly alleviating the interference across subjects. Both qualitative and quantitative experimental results demonstrate our superiority over state-of-the-art alternatives under a variety of settings for multi-subject customization.     </p>

<hr>
<!--  <p class="section">&nbsp;</p>-->
    <p class="section"><b>Method</b></p>
      <div class="container">
<table align="center" width="940" border="0">
  <tbody>
  <!--    <tr>
   <td><p style="margin-top: -12px;">
          Our key idea is to define a new generation process over a pre-trained reference diffusion model.
          Starting from a noise image, at each generation step, we solve an optimization task whose objective is that each crop
          will follow as closely as possible its denoised version.
      </p></td>
    </tr>-->
    <tr>
      <td><img src="arch.jpg" alt="" width="1000" /></td>
    </tr>
  </tbody>
</table>
<br>
          <table align="" width="940" border="0">
  <tbody>
	  
    <tr>
      <td><p>
          (a) Given few-shot images of the customized subject, we fine-tune the text encoder to learn a residual embedding on top of the base embedding of raw subject.
        (b) Based on the residual embeddings, we then propose to employ layout as the spatial guidance for subject arrangement into the attention maps. After that, we could strengthen the signal of target subjects and weaken the signal of irrelevant subjects.  </p></td>
    </tr>
   <!--  <tr>
      <td style="padding-left: 75px">
        <video height="250" playsinline="" autoplay="" loop="" preload="" muted=""> <source src="pics/fusing.mp4" type="video/mp4"> </video>
      </td>
    </tr>-->
  </tbody>
</table>
<hr>
<p class="section"><b>Comparison</b></p>
<p class="section" style="font-size: 120%"><b>Two customized subjects</b></p>
<!--      <div class="container">-->
	<table align="center" width="940" border="0">
  	<tbody>
	  
    <tr>
      <td><img src="two2.png" alt="" width="1000" /></td>
    </tr>
		  </tbody>
	</table><br>	
  <p class="section" style="font-size: 120%"><b>Three customized subjects</b></p>
<!--      <div class="container">-->
	<table align="center" width="940" border="0">
  	<tbody>
	  
    <tr>
      <td><img src="three3.png" alt="" width="1000" /></td>
    </tr>
		  </tbody>
	</table><br>	
  <p class="section" style="font-size: 120%"><b>Four customized subjects</b></p>
<!--      <div class="container">-->
	<table align="center" width="940" border="0">
  	<tbody>
	  
    <tr>
      <td><img src="four4.png" alt="" width="1000" /></td>
    </tr>
		  </tbody>
	</table><br>	
	      <hr>
  <!-- <p class="section" style="font-size: 120%"><b>Tight region-based generation</b></p>
    <div class="container">-->
	


<p class="section"><b>More challenging cases</b></p>
<p>
  Here we present diverse generated images of multiple customized subjects, further demonstrating the effectiveness of Cones 2.</p>
<div class="container">
<table align="center" width="940" border="0">
<tbody>
<!--    <tr>
<td><p style="margin-top: -12px;">
    Our key idea is to define a new generation process over a pre-trained reference diffusion model.
    Starting from a noise image, at each generation step, we solve an optimization task whose objective is that each crop
    will follow as closely as possible its denoised version.
</p></td>
</tr>-->
<tr>
<td><img src="more.png" alt="" width="1000" /></td>
</tr>
</tbody>
</table>
<br>
    <table align="" width="940" border="0">
<tbody>

<!--  <tr>
<td style="padding-left: 150px">
  <video height="500" playsinline="" autoplay="" loop="" preload="" muted=""> <source src="pics/fusing.mp4" type="video/mp4"> </video>
</td>
</tr>-->
</tbody>
</table>
<hr>


    <script>



        let slideIndex = 1;
showSlides(slideIndex);

// Next/previous controls
function plusSlides(n) {
  showSlides(slideIndex += n);
}

// Thumbnail image controls
function currentSlide(n) {
  showSlides(slideIndex = n);
}

function showSlides(n) {
  let i;
  let slides = document.getElementsByClassName("mySlides");
  let dots = document.getElementsByClassName("dot");
  if (n > slides.length) {slideIndex = 1}
  if (n < 1) {slideIndex = slides.length}
  for (i = 0; i < slides.length; i++) {
    slides[i].style.display = "none";
  }
  for (i = 0; i < dots.length; i++) {
    dots[i].className = dots[i].className.replace(" active", "");
  }
  slides[slideIndex-1].style.display = "block";
  dots[slideIndex-1].className += " active";
}
    </script>

</body>
</html>
